{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a63cef3-de63-4558-aec3-3d9efd32108d",
   "metadata": {},
   "source": [
    "# The Quadrilingual Land of Lonpestia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c350e36-a3c7-492d-bfa3-923e825660ea",
   "metadata": {},
   "source": [
    "In a land far, far away, there lies a country with four official languages: Englcrevbeh, Hungeleabeen, En Gli and Hure. The locals can understand each other no problem, even those that speak different languages, but the same cannot be said for you, a simple tourist in the harsh lands of Lonpestia.\n",
    "\n",
    "All of the locals in Lonpestia become extremely angry if you assume they belong to a different demographic, so you need to be able to correctly identify what language people are speaking in order to safely ask for directions and survive your vacation.\n",
    "\n",
    "## Train & Test Data\n",
    "\n",
    "There is no train data. ðŸ™‚\n",
    "\n",
    "The test data is a series of texts in the four languages spoken in Lonpestia:\n",
    "\n",
    "- Englcrevbeh\n",
    "- Hungeleabeen\n",
    "- En Gli\n",
    "- Hure\n",
    "\n",
    "## Task\n",
    "\n",
    "To start off, you will need to correctly identify if two people are speaking the same language in a conversation. If not, you won't be able to approach them for directions, because at least one of them will attack you.\n",
    "\n",
    "### Subtask 1 â€“ Monolingual Conversations (30p)\n",
    "\n",
    "You are given a series of data points in the following format: `datapointID`, `textA`, `textB`. Your task is to create a submission that, for each datapoint in this subtask, specifies whether textA and textB are the same language or not.\n",
    "\n",
    "Once you have confirmed that a conversation is monolingual, you need to figure out which language to approach the locals with!\n",
    "\n",
    "### Subtask 2 â€“ Language Identification (70p)\n",
    "\n",
    "You are given a series of data points in the following format: `datapointID`, `textA`, `textB` where `textB` is always missing. Your task is to create a submission that, for each datapoint, returns the language that the `textA` is in. `textB` can be safely disregarded for this subtask.\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Your submission must be in the following format: `datapointID`, `subtaskID`, `answer`, where the rows in the .csv file are 1 or 2 in the `subtaskID` column depending on the subtask that you are solving.\n",
    "\n",
    "The `answer` column must contain:\n",
    "\n",
    "- either `true` or `false` for rows corresponding to the first subtask.\n",
    "- one of `Englcrevbeh`, `Hungeleabeen`, `En Gli` or `Hure` for rows corresponding to the second subtask.\n",
    "- \n",
    "Values in the `answer` column are case-insensitive. For example, for the first subtask, `true`, `True` and `tRue` are all accepted as `true`, while for the second subtask, `engLCRevbeh` is also acceptable instead of `Englcrevbeh`, but `EnGli` is not acceptable instead of `En Gli`.\n",
    "\n",
    "The `datapointID` column must match the datapoint from test_data.csv that you are solving.\n",
    "\n",
    "## Scoring\n",
    "\n",
    "The first subtask is scored as follows:\n",
    "\n",
    "- F1 < 0.65 â†’ 2 points.\n",
    "- 0.65 <= F1 < 0.85 â†’ 10-20 points.\n",
    "- 0.85 <= F1 â†’ 30 points.\n",
    "\n",
    "The second subtask is scored as follows:\n",
    "\n",
    "- Accuracy < 0.4 â†’ 3 points.\n",
    "- 0.4 <= Accuracy < 0.8 â†’ 10-60 points.\n",
    "- 0.8 <= Accuracy < 0.95 â†’ 65 points.\n",
    "- 0.95 <= Accuracy â†’ 70 points.\n",
    "\n",
    "## Editorial\n",
    "\n",
    "[Editorial.](https://gitlab.com/nitronlp/judge-editorials/-/wikis/Cram-School-PreONIA-2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e23244c-0782-4f30-aad6-26702e4dabf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0848692-2824-4fea-bf60-b98ca7ce24e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datapointID</th>\n",
       "      <th>textA</th>\n",
       "      <th>textB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120</td>\n",
       "      <td>o utse airs eaien eii llin cri.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1168</td>\n",
       "      <td>e str er's ga ii hie ied al wi e aad en swih e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>796</td>\n",
       "      <td>den diin eipri skis, eie ren ers ie taend ie c...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>he e kekcleazologuclea nem e hejen eleajecleaz...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>licrhcrevbe coheleaenlicr gleaoup crhiileaed i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>782</td>\n",
       "      <td>e eldi taams i event r uns ae diii ers (i ee i...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>416</td>\n",
       "      <td>elegucleagucleauk eclea felegucleagucleauk cle...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>760</td>\n",
       "      <td>hev er, iis eded ieet urn, wi e t20 iraif ee, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>656</td>\n",
       "      <td>hbele ciicrlicrlecr eleae ucred licro hold ii ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>628</td>\n",
       "      <td>ben crome counlicrleabeecr licrhe moniileach h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datapointID                                              textA textB\n",
       "0             120                    o utse airs eaien eii llin cri.   NaN\n",
       "1            1168  e str er's ga ii hie ied al wi e aad en swih e...   NaN\n",
       "2             796  den diin eipri skis, eie ren ers ie taend ie c...   NaN\n",
       "3             114  he e kekcleazologuclea nem e hejen eleajecleaz...   NaN\n",
       "4             989  licrhcrevbe coheleaenlicr gleaoup crhiileaed i...   NaN\n",
       "...           ...                                                ...   ...\n",
       "1582          782  e eldi taams i event r uns ae diii ers (i ee i...   NaN\n",
       "1583          416  elegucleagucleauk eclea felegucleagucleauk cle...   NaN\n",
       "1584          760  hev er, iis eded ieet urn, wi e t20 iraif ee, ...   NaN\n",
       "1585          656  hbele ciicrlicrlecr eleae ucred licro hold ii ...   NaN\n",
       "1586          628  ben crome counlicrleabeecr licrhe moniileach h...   NaN\n",
       "\n",
       "[1587 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699cdfe-e170-4343-953a-c410ec9cce83",
   "metadata": {},
   "source": [
    "## Subtask 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f22cfd1-d2c4-4b91-b2a7-a92e02335165",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df['textB'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77cc555-8e37-4b17-8b4c-3cb5dbbd9e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e61b42-6cdc-4e60-bbda-115ad0cead0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask1_rows = []\n",
    "\n",
    "for idx, row in df1.iterrows():\n",
    "    vectors = vectorizer.fit_transform([row['textA'], row['textB']])\n",
    "    sim = cosine_similarity(vectors[0], vectors[1])[0, 0]\n",
    "    \n",
    "    same_lang = sim > 0.4\n",
    "    subtask1_rows.append([1, row['datapointID'], str(same_lang)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1b5c6-1b25-462d-a578-3c7d140c5516",
   "metadata": {},
   "source": [
    "## Subtask 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "541e10ea-783f-4f26-920e-6c012ff1b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df[\"textB\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8354572-c2c0-4611-a7fe-25e4e60251d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = [\"Englcrevbeh\", \"Hungeleabeen\", \"En Gli\", \"Hure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04251890-aea0-4e7a-97b1-bacfdf8f5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df2[\"textA\"].tolist()\n",
    "vectors = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b41df5de-b057-4ee4-a05a-fab06693c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(3)\n",
    "vectors = pca.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b88d9b68-15e1-4c9f-afb5-02ba7f04555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=len(langs), random_state=42)\n",
    "clusters = kmeans.fit_predict(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "403a3789-d094-4c85-a2f5-079627c1288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_vectors = vectorizer.transform(langs)\n",
    "lang_vectors = pca.transform(lang_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cdb2363-c684-463f-a5fb-2cc99e3ca9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 0, 2, 3), np.float64(1.4518432190427306))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_perm = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for perm in permutations(range(4)):\n",
    "    l_perm = lang_vectors[list(perm)]\n",
    "    sim_matrix = cosine_similarity(kmeans.cluster_centers_, l_perm)\n",
    "    score = np.trace(sim_matrix)  # sum of diagonal elements (pairwise sim)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_perm = perm\n",
    "best_perm, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "423d6487-e63b-4c68-a43e-1d587817ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtask2_rows = []\n",
    "\n",
    "for did, cidx in zip(df2['datapointID'], clusters):\n",
    "    lang = langs[best_perm[cidx]]\n",
    "    subtask2_rows.append([2, did, lang])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6837150-95f6-4c07-a641-6532b15201d2",
   "metadata": {},
   "source": [
    "## Save answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e16164-98ce-4447-aa4a-550be7a7645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_rows = subtask1_rows + subtask2_rows\n",
    "df_submission = pd.DataFrame(submission_rows, columns=[\"subtaskID\", \"datapointID\", \"answer\"])\n",
    "df_submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e6509-d5fa-453a-b378-70aa9c384a6e",
   "metadata": {},
   "source": [
    "## Submission results\n",
    "\n",
    "Subtask 1:\n",
    "- F1 Score: 0.85475\n",
    "- Score: 30/30\n",
    "\n",
    "Subtask 2:\n",
    "- Accuracy: 0.978172\n",
    "- Score: 70/70"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
