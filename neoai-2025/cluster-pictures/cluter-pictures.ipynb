{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend\n",
    "\n",
    "## Slava's glass. Pt. 3\n",
    "\n",
    "Slava walked down the corridor, clutching his trophy ‚Äî the Glass. The twisted halls were behind him, traps dismantled, Bayesian illusions avoided. Ahead ‚Äî a heavy wooden door with a sign that read \"Exit.\" Freedom. Victory. Light.\n",
    "\n",
    "But just as he reached for the handle, the air shimmered. The walls groaned, and the scent of chalk filled the space, as if someone had just solved an infinite system of equations.\n",
    "Out of the shadows stepped Roman ‚Äî draped in a black robe, a scroll under his arm, and eyes sharp enough to slice through any neural net.\n",
    "\n",
    "Slava knew him. Knew him from the university days.\n",
    "They said Roman could prove a theorem before it was even formulated.\n",
    "They said he could see the loss function of reality.\n",
    "The Mathematical Mage.\n",
    "\n",
    "‚Äî ‚ÄúWanna play a game?‚Äù Roman asked, and with a flick of his wrist, the Glass vanished from Slava‚Äôs hand and reappeared in Roman‚Äôs.\n",
    "\n",
    "‚Äî ‚ÄúNot bad. You escaped my labyrinth. But if you want to leave this place with your precious...‚Äù\n",
    "He tossed the glass and caught it casually.\n",
    "\n",
    "‚Äî ‚ÄúYou‚Äôll have to impress me.‚Äù\n",
    "\n",
    "From his sleeve, Roman pulled out a deck of old cards. He snapped his fingers ‚Äî and the deck exploded into glowing fragments, scattering through the room like data points in chaos.\n",
    "\n",
    "‚Äî ‚ÄúBring me this deck ‚Äî whole, complete, and intact. Not just gathered. Understood.‚Äù\n",
    "\n",
    "Slava took a deep breath. He knew this was the final challenge. The hardest one.\n",
    "He opened his laptop, put on his headphones ‚Äî and in his ears began the final lines of Al Pacino‚Äôs legendary speech:\n",
    "\n",
    "‚ÄúI mean one-half a step too late, or too early, and you don‚Äôt quite make it. One-half second too slow, too fast, you don‚Äôt quite catch it. The inches we need are everywhere around us. They‚Äôre in every break of the game, every minute, every second. On this team, we fight for that inch. On this team, we tear ourselves and everyone else around us to pieces for that inch. We claw with our fingernails for that inch, because we know when we add up all those inches that‚Äôs gonna make the f**** difference between winning and losing! Between livin' and dyin'!‚Äù\n",
    "\n",
    "He hit Enter.\n",
    "\n",
    "üß© Your Task:\n",
    "You are given a set of arrays, where each array represents an image. The images have been augmented. It is known that all data comes from 32 original images, each one followed by several transformed versions.\n",
    "Your goal is to cluster these arrays.\n",
    "\n",
    "Slava looked at the scattered card fragments.\n",
    "\n",
    "‚Äî ‚ÄúThe game‚Äôs not over yet.‚Äù\n",
    "\n",
    "## Overview\n",
    "\n",
    "You are given two sets of arrays, **X‚ÇÅ** and **X‚ÇÇ**. Each row in both arrays corresponds to the **same image** (these arrays represent its features). Your task is to cluster the given images. It is known that there are **32 clusters**. Additionally, each original image has been **augmented multiple times**, and the augmented versions have been added to the dataset.\n",
    "\n",
    "## Metric\n",
    "\n",
    "[adjusted_rand_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html).\n",
    "\n",
    "## Restriction\n",
    "\n",
    "If you want to use a neural network, you can only use the neural network below ‚Äì EmbNet. You can't change anything inside the neural network class. You **can't fine-tune the model** and change the weights.\n",
    "\n",
    "## `sample_submission_cluster.csv`\n",
    "\n",
    "`sample_submission_cluster.csv` consists of a column ID, where the value is the row number in the dataset, and target columns with your predictions of clusters.\n",
    "\n",
    "===\n",
    "\n",
    "When you make a submit, make a Quick Save of the notebook, otherwise we may reject your solution.\n",
    "\n",
    "You must solve this task on KAGGLE (YOU CAN'T USE CLOUD.RU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model('tiny_vit_5m_224.dist_in22k_ft_in1k', pretrained=True, num_classes=0)\n",
    "\n",
    "    def forward(self, image):\n",
    "        x = self.model(image)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submit(pred_cluster):\n",
    "    import hashlib\n",
    "    \n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = np.arange(len(pred_cluster))\n",
    "    sub['target'] = pred_cluster\n",
    "    \n",
    "    hsh = hashlib.sha256(sub.to_csv(index=False).encode('utf-8')).hexdigest()[:8]\n",
    "    submit_path = f\"submit_{hsh}.csv\"\n",
    "    \n",
    "    print(f\"SUBMIT_NAME: {submit_path}\")\n",
    "    print(sub.head(10))\n",
    "    sub.to_csv(submit_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3840, 128, 4), (3840, 4, 128))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1 = np.load('data_1.npz')\n",
    "X_1 = X_1.f.arr_0\n",
    "X_2 = np.load('data_2.npz')\n",
    "X_2 = X_2.f.arr_0\n",
    "\n",
    "X_1.shape, X_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3840/3840 [00:03<00:00, 1226.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3840, 3, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = []\n",
    "for x_1, x_2 in tqdm(zip(X_1, X_2), total=len(X_1)):\n",
    "    pseudo_img = np.stack([\n",
    "        cv2.resize(x_1, (224, 224)),\n",
    "        cv2.resize(x_2, (224, 224)),\n",
    "        cv2.resize((x_1 @ x_2), (224, 224))\n",
    "    ], axis=0)\n",
    "    X_tensor.append(torch.tensor(pseudo_img))\n",
    "\n",
    "X_tensor = torch.stack(X_tensor, dim=0)\n",
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = EmbNet().to(device)\n",
    "net.model.eval();\n",
    "\n",
    "dl_X = DataLoader(X_tensor.to(device), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 240/240 [00:08<00:00, 27.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3840, 320)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb = []\n",
    "with torch.no_grad():\n",
    "    for batch_X in tqdm(dl_X):\n",
    "        batch_X_emb = net(batch_X)\n",
    "        X_emb.append(batch_X_emb.detach().cpu().numpy())\n",
    "\n",
    "X_emb = np.vstack(X_emb)\n",
    "X_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(10, random_state=42)\n",
    "X_emb_pca = pca.fit_transform(X_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]),\n",
       " array([199, 164,  81, 128, 134, 176, 118, 133, 134,  63, 138, 114, 107,\n",
       "        122, 148,  38, 135,  67, 139, 127,  65, 166, 104,  93, 141, 142,\n",
       "         73, 135, 122,  57, 200,  77], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(32, random_state=42)\n",
    "pred_cluster = km.fit_predict(X_emb_pca)\n",
    "np.unique(pred_cluster, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUBMIT_NAME: submit_fff2b404.csv\n",
      "   id  target\n",
      "0   0      24\n",
      "1   1       1\n",
      "2   2      30\n",
      "3   3       0\n",
      "4   4      22\n",
      "5   5      25\n",
      "6   6       6\n",
      "7   7       3\n",
      "8   8       8\n",
      "9   9      11\n"
     ]
    }
   ],
   "source": [
    "generate_submit(pred_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score\n",
    "\n",
    "- Private: 0.07474\n",
    "- Public: 0.07916\n",
    "\n",
    "> Baseline: (`random_state=42`)\n",
    "> - Private: 0.02911\n",
    "> - Public: 0.02857\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12163515,
     "sourceId": 101035,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
