{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwe8DCInoB6g"
   },
   "source": [
    "# üí• Implicit Toxic Comment Detection ‚Äì Task Overview\n",
    "\n",
    "This notebook provides a baseline solution for detecting **toxic language** in social media text using PyTorch and TorchText. The main goal is to classify each input as either **toxic (1)** or **non-toxic (0)**, based on linguistic patterns learned from labeled examples.\n",
    "\n",
    "## 1. üß© Problem\n",
    "\n",
    "The goal is to detect **implicit toxic language** in social media posts, particularly tweets. The task is framed as a **binary classification** problem:  \n",
    "> Predict whether a given text is **toxic (1)** or **non-toxic (0)**.\n",
    "\n",
    "## 2. üìö Dataset Description\n",
    "\n",
    "The pre-processed dataset is sourced from the [**ToxicDet Datasets** repository](https://github.com/duyngtr16061999/toxicdet_datasets) and contains four CSV files:\n",
    "\n",
    "| File             | Description                                                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|\n",
    "| `train.csv`      | Labeled training data with two columns: `text` (input sentence) and `label` (1 = toxic, 0 = non-toxic). |\n",
    "| `unlabeled.csv`  | Unlabeled training samples‚Äîuseful for semi-supervised learning.             |\n",
    "| `test.csv`       | Evaluation set with known labels for local validation.                      |\n",
    "| `hidden_test.csv`| The final test set used for leaderboard evaluation. No labels are provided. |\n",
    "\n",
    "## 3. üß† Implemented base model\n",
    "\n",
    "The baseline model in this notebook uses:\n",
    "\n",
    "- **TorchText** for preprocessing and vocabulary building\n",
    "- **RNN-based classifier**: an embedding layer, a hidden rnn layer (where the recurrent connection occurs), and an output layer (fully connected neural network).\n",
    "- Training via **PyTorch**: using Adam optimizer and cross-entropy loss for training objective.\n",
    "- Optional extensions with pretrained embeddings (e.g., GloVe, FastText)\n",
    "\n",
    "## 4. üßæ Input and output of the model\n",
    "\n",
    "- **Input**: A single text comment (string).\n",
    "  - A tokenized sequence using a vocabulary-based tokenizer (from TorchText)\n",
    "  - The **length** of the tokenized sequence (used for batching and masking in models like RNNs)\n",
    "- **Output**: A binary label:\n",
    "  - `1` ‚Üí toxic / implicit hate\n",
    "  - `0` ‚Üí non-toxic\n",
    "\n",
    "## 5. üìè What metric is used?\n",
    "\n",
    "The primary evaluation metric is **Accuracy**:\n",
    "> Accuracy = (Correct Predictions) / (Total Samples)\n",
    "\n",
    "This metric will be computed on both `test.csv` and `hidden_test.csv`.\n",
    "\n",
    "## 6. üéØ Task for Students\n",
    "\n",
    "You are tasked with **improving the toxic comment classification model**. You are free to implement any model you want. Some suggestions (but not compulsary) including:\n",
    "\n",
    "1. **Model Improvements**:\n",
    "   - Enhance the baseline using more advanced models like BiLSTM, CNN, Transformer-based models (e.g., BERT, PhoBERT).\n",
    "   - Consider pretrained embeddings or language models to boost performance.\n",
    "\n",
    "2. **Semi-Supervised Learning**:\n",
    "   - Use `unlabeled.csv` to create pseudo-labels or apply consistency-based regularization.\n",
    "   - Experiment with self-training or co-training frameworks.\n",
    "\n",
    "4. **Evaluation and Tuning**:\n",
    "   - Validate your models thoroughly on `test.csv`.\n",
    "   - Tune hyperparameters for better generalization to `hidden_test.csv`.\n",
    "\n",
    "## 7. üì§ Submission Instructions\n",
    "\n",
    "- The code will save the results in a file named `predictions.csv`.  \n",
    "  ‚úÖ Please rename it to: `submission_<your_name>.csv` before uploading to the competition platform.\n",
    "- You must also submit the notebook file (`.ipynb`) containing your training and inference code.  \n",
    "  ‚úÖ Rename it to: `notebook_<your_name>.ipynb`.\n",
    "- ‚ùå **Do not submit any model checkpoint files** (e.g., `.pt`, `.bin`, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "J7gzVWug_vdQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'toxicdet_datasets' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/duyngtr16061999/toxicdet_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\OneDrive\\Documents\\data\\ioai-tsp-2025-jaredliw\\noai-singapore-2025\\toxic-comment\\.venv\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "C:\\Users\\ASUS\\OneDrive\\Documents\\data\\ioai-tsp-2025-jaredliw\\noai-singapore-2025\\toxic-comment\\.venv\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NbbaE7gH_vdQ"
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3908, 11727)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path(\"./toxicdet_datasets\")\n",
    "\n",
    "df_train = pd.read_csv(base_dir / \"train.csv\")\n",
    "df_train_unlabeled = pd.read_csv(base_dir / \"unlabeled.csv\")\n",
    "df_test = pd.read_csv(base_dir / \"test.csv\")\n",
    "df_test_unlabeled = pd.read_csv(base_dir / \"hidden_test.csv\")\n",
    "\n",
    "len(df_train), len(df_train_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>republicans like the ones the gop tries to fob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>. feature : legal alliance gains host of court...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>black thug attacks old white man with urine be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it's outrageous that good journalists would wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a cm or his ministers behaving like street-goo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  republicans like the ones the gop tries to fob...      0\n",
       "1  . feature : legal alliance gains host of court...      1\n",
       "2  black thug attacks old white man with urine be...      0\n",
       "3  it's outrageous that good journalists would wh...      0\n",
       "4  a cm or his ministers behaving like street-goo...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts, vocab=None, *, max_len=500, vocab_size=10000):\n",
    "    # Tokenize\n",
    "    text_tokens = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "    # Build vocabulary\n",
    "    vocab_provided = vocab is not None\n",
    "    if not vocab_provided:\n",
    "        common_words = Counter([token for text in text_tokens for token in text]).most_common(vocab_size - 2)\n",
    "        vocab = {word: idx + 2 for idx, (word, _) in enumerate(common_words)}\n",
    "        vocab[\"<UNK>\"] = 1\n",
    "        vocab[\"<PAD>\"] = 0\n",
    "\n",
    "    # Tokens to token IDs\n",
    "    text_token_ids = []\n",
    "    for text in text_tokens:\n",
    "        encoded = [vocab.get(word, vocab[\"<UNK>\"]) for word in text]\n",
    "        # Truncate if more, pad if less\n",
    "        encoded += [vocab[\"<PAD>\"]] * (max_len - len(encoded))\n",
    "        encoded = encoded[:max_len]\n",
    "        text_token_ids.append(encoded)\n",
    "    text_token_ids = torch.tensor(text_token_ids).to(device)\n",
    "    \n",
    "    if vocab_provided:\n",
    "        return text_token_ids\n",
    "    return text_token_ids, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9245"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, vocab = preprocess(df_train[\"text\"])\n",
    "y_train = df_train[\"label\"]\n",
    "\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = preprocess(df_train_unlabeled[\"text\"], vocab)\n",
    "X_test, y_test = preprocess(df_test[\"text\"], vocab), df_test[\"label\"]\n",
    "X_test1 = preprocess(df_test_unlabeled[\"text\"], vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx] if self.labels is not None else self.texts[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = TextDataset(X_train, y_train)\n",
    "dl_train = DataLoader(ds_train, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train1 = TextDataset(X_train1)\n",
    "dl_train1 = DataLoader(ds_train1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = TextDataset(X_test, y_test)\n",
    "dl_test = DataLoader(ds_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test1 = TextDataset(X_test1)\n",
    "dl_test1 = DataLoader(ds_test1, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes, padding_idx=0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(2 * hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, cell) = self.lstm(embedded)\n",
    "        last_hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "        logits = self.fc(last_hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, dataloader, num_epochs, eval_dataloader=None, model_filename=\"best_lstm.pt\"):\n",
    "    train_losses = []\n",
    "    highest_accuracy = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        running_loss /= len(dataloader.dataset)\n",
    "        train_losses.append(running_loss)\n",
    "        \n",
    "        accuracy = evaluate(model, dataloader)\n",
    "        score = accuracy\n",
    "        if eval_dataloader is not None:\n",
    "            score = evaluate(model, eval_dataloader)\n",
    "            accuracy = [accuracy, score]\n",
    "\n",
    "        if score > highest_accuracy:\n",
    "            torch.save(model.state_dict(), model_filename)\n",
    "            highest_accuracy = score\n",
    "        \n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss}, Accuracy: {accuracy}\")\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probas = []\n",
    "    for inputs, _ in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        \n",
    "        outputs = model(inputs).squeeze()\n",
    "        outputs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.append(preds)\n",
    "        all_probas.append(outputs[torch.arange(outputs.size(0)), preds])\n",
    "\n",
    "    return torch.hstack(all_preds), torch.hstack(all_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        preds, _ = predict(model, [(inputs, None)])\n",
    "        \n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "\n",
    "model = MyModel(len(vocab), embedding_dim, hidden_dim, 2, vocab[\"<PAD>\"]).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = GloVe(dim=embedding_dim)\n",
    "embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
    "\n",
    "for word, idx in vocab.items():\n",
    "    if word in glove.stoi:\n",
    "        embedding_matrix[idx] = glove[word].numpy()\n",
    "    else:\n",
    "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
    "\n",
    "model.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
    "model.embedding.requires_grad_(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6069801191712597, Accuracy: [0.7320880245649949, 0.6860940695296524]\n",
      "Epoch [2/10], Loss: 0.5253773936534734, Accuracy: [0.7750767656090072, 0.7290388548057259]\n",
      "Epoch [3/10], Loss: 0.47478856642024175, Accuracy: [0.79503582395087, 0.7326175869120655]\n",
      "Epoch [4/10], Loss: 0.43032087228178, Accuracy: [0.8208802456499488, 0.7367075664621677]\n",
      "Epoch [5/10], Loss: 0.37666725930104844, Accuracy: [0.8349539406345957, 0.7392638036809815]\n",
      "Epoch [6/10], Loss: 0.33917839367975966, Accuracy: [0.8592630501535312, 0.7351738241308794]\n",
      "Epoch [7/10], Loss: 0.29498731748257195, Accuracy: [0.8902251791197543, 0.7065439672801636]\n",
      "Epoch [8/10], Loss: 0.22462493440368905, Accuracy: [0.8359774820880246, 0.7356850715746421]\n",
      "Epoch [9/10], Loss: 0.22999919789934772, Accuracy: [0.9124872057318322, 0.7167689161554193]\n",
      "Epoch [10/10], Loss: 0.18234349896644214, Accuracy: [0.9347492323439099, 0.7183026584867076]\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, dl_train, 10, dl_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7392638036809815"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = deepcopy(model)\n",
    "best_model.load_state_dict(torch.load(\"best_lstm.pt\"))\n",
    "best_model.lstm.flatten_parameters()  # Flatten weights in a single block of memory (for CuDNN optimization)\n",
    "\n",
    "score = evaluate(best_model, dl_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9647"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = 0.85\n",
    "\n",
    "preds, probas = predict(model, dl_train1)\n",
    "mask = probas >= threshold\n",
    "\n",
    "mask.sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train1_pseu = TextDataset(X_train1[mask], preds[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13555"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train_extended = ConcatDataset([ds_train, ds_train1_pseu])\n",
    "dl_train_extended = DataLoader(ds_train_extended, batch_size=64)\n",
    "\n",
    "len(ds_train_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.11833385116410723, Accuracy: [0.9692364441165622, 0.712678936605317]\n",
      "Epoch [2/10], Loss: 0.07239131128318589, Accuracy: [0.9692364441165622, 0.717280163599182]\n",
      "Epoch [3/10], Loss: 0.0567424925826751, Accuracy: [0.9742530431575065, 0.7131901840490797]\n",
      "Epoch [4/10], Loss: 0.04117908401896388, Accuracy: [0.9721873847288823, 0.7177914110429447]\n",
      "Epoch [5/10], Loss: 0.0378376873827705, Accuracy: [0.9713021025451862, 0.7229038854805726]\n",
      "Epoch [6/10], Loss: 0.037005999634482624, Accuracy: [0.9803762449280709, 0.7131901840490797]\n",
      "Epoch [7/10], Loss: 0.04195667778635885, Accuracy: [0.9772039837698266, 0.7111451942740287]\n",
      "Epoch [8/10], Loss: 0.03882673933668518, Accuracy: [0.9811877535964588, 0.7223926380368099]\n",
      "Epoch [9/10], Loss: 0.027516346048409215, Accuracy: [0.9855403909996311, 0.7116564417177914]\n",
      "Epoch [10/10], Loss: 0.028740759741178085, Accuracy: [0.983548506086315, 0.7203476482617587]\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, dl_train_extended, 10, dl_test, \"best_lstm_pseu.pt\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7229038854805726"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_pseu = deepcopy(model)\n",
    "best_model_pseu.load_state_dict(torch.load(\"best_lstm_pseu.pt\"))\n",
    "best_model_pseu.lstm.flatten_parameters()\n",
    "\n",
    "score_pseu = evaluate(best_model_pseu, dl_test)\n",
    "score_pseu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = best_model_pseu if score_pseu >= score else best_model\n",
    "\n",
    "hidden_predictions, _ = predict(model, dl_test1)\n",
    "hidden_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "z1kzRQUc_vdS"
   },
   "outputs": [],
   "source": [
    "def save_predictions_to_csv(dataset, filename):\n",
    "    with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['label'])\n",
    "        for item in dataset:\n",
    "            writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "g2TKmuEC_vdS"
   },
   "outputs": [],
   "source": [
    "# Save the output DataFrame to a CSV file\n",
    "your_name = \"wlamb\"  # <- IMPORTANT: Replace with your name\n",
    "csv_filename = f\"prediction_{your_name}.csv\"\n",
    "save_predictions_to_csv(hidden_predictions.tolist(), csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qggGRwk0cl98"
   },
   "source": [
    "## **IMPORTANT**: Remember to Download both your Notebook and Output csv file and submit using the NLP Submission Link.\n",
    "\n",
    "Make sure both files are name correctly.  \n",
    "\n",
    "For example:\n",
    "- `JohnSmith-IOAI2025-Task3-NaturalLanguageProcessing.ipynb`.\n",
    "- `predictions_JohnSmith.csv`."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "IOAI2025-Task3-NaturalLanguageProcessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
