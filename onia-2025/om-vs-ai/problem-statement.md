# ðŸ§” Human vs AI ðŸ¤–

## Prompt

In a world where almost everyone uses AI models like ChatGPT to generate content, it is becoming increasingly difficult to distinguish between text written by a human and that generated automatically. At the same time, identifying the main subject of a text remains essential for organizing and interpreting information.

The goal of this exercise is twofold:

- **Subtask 1:** Detecting the source of a text â€“ is it written by a human or generated by AI?
- **Subtask 2:** Classifying the text into one of four major themes: science, business, religion, or crime.

## Dataset

The input file contains a table with the following columns:

- `ID` â€“ a unique identifier for each sentence.
- `text` â€“ the actual sentence.
- `label` â€“ the source of the text (0 if written by a human, 1 if generated by AI).

### Subtask 1 â€“ Detecting the source of the text (AI vs. Human)

A binary classification model will be trained using the data in the `train_data.csv` file. It receives a text as input and returns:

- **0** if the text was written by a **human**.
- **1** if the text was generated by **AI**.

Using this model, you will predict the source for all texts in `test_data.csv` that have a value of 1 in the `subtaskID` column.

## Subtask 2 â€“ Classifying the theme of the texts

For each text, you will determine its main theme by classifying it into one of the following four categories:

- "SCIENCE"
- "BUSINESS"
- "CRIME"
- "RELIGION"

**The `train_data.csv` dataset does not directly contain these thematic labels.**

The methods you develop will only be applied to the texts in `test_data.csv` that have a value of 2 in the `subtaskID` column.

## Output file format

The model will generate a .csv file named `output.csv`, with the following 3 columns:

- `subtaskID` â€“ 1 for text source (AI vs. Human), 2 for thematic classification.
- `datapointID` â€“ the value from the `ID` column of the input text.
- `answer` â€“ the label predicted by the model (numeric format: 0/1 for Subtask 1 or string for Subtask 2).

Example of `output.csv`:

```csv
subtaskID,datapointID,answer  
1,101,0  
1,102,1  
2,101,SCIENCE  
2,102,CRIME  
...
```

For the full format, refer to the `sample_output.csv` file.

## Training file â€“ `train_data.csv`

Column format:

| Column   | Type | Description                               |
|----------|------|-------------------------------------------|
| `ID`     | int  | Unique identifier for each text instance. |
| `text`   | str  | The sentence or paragraph to be analyzed. |
| `label`  | int  | The label associated with the text (0/1). |

Examples:

```csv
ID,text,label  
1,This text is generated by AI.,1  
2,This is a sentence written by a human.,0
```

## Test file â€“ `test_data.csv`

Column format:

| Column      | Type | Description                                                   |
|-------------|------|---------------------------------------------------------------|
| `ID`        | int  | Unique identifier for each text instance.                     |
| `subtaskID` | int  | Value 1 or 2, indicating which subtask the prediction is for. |
| `text`      | str  | The sentence or paragraph to be classified.                   |

## Summary

| File        | Purpose                     | Columns                   |
|-------------|-----------------------------|---------------------------|
| `train.csv` | Model training              | `ID`, `text`, `label`     |
| `test.csv`  | Prediction + classification | `ID`, `subtaskID`, `text` |

## Scoring

### Subtask 1 â€“ AI vs Human classification (F1-score)

| F1-score (%) | Awarded Score     |
|--------------|-------------------|
| â‰¥ 95         | 60 points         |
| 70 â€“ 94.99   | between 10 and 50 |
| < 70         | 0 points          |

The score is calculated using the macro-averaged F1 score and linearly interpolated within the corresponding interval.

### Subtask 2 â€“ Thematic classification (Accuracy)

| Accuracy (%) | Awarded Score     |
|--------------|-------------------|
| < 25         | 5 points          |
| 25 â€“ 49.99   | between 5 and 10  |
| 50 â€“ 79.99   | between 10 and 20 |
| 80 â€“ 96.99   | between 20 and 35 |
| â‰¥ 97         | 40 points         |

Accuracy (`accuracy_score`) is converted to a score via linear interpolation within the appropriate range.

> This is an English translation of the original Romanian task description, generated by ChatGPT.
