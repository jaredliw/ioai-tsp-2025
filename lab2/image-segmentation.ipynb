{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqq1CsOlLPXb"
   },
   "source": [
    "# Assembling a FCN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSedilSPMoeW"
   },
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vyCzMbsMqaF"
   },
   "outputs": [],
   "source": [
    "!curl https://storage.googleapis.com/aiolympiadmy/ioai-2025-tsp/leaf-segmentation-dataset.zip -o leaf-segmentation-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip leaf-segmentation-dataset.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is given to you in a `trainval/` and `test/` subdir. Images are named `*_rgb.png` while their foreground masks (_what does this mean?_) are given in `*_fg.png`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this section to figure out what you need / want to know about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your dataset and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've done the Pytorch 60 mins blitz right? Implement your dataset and dataloaders here. From the `trainval/` folder, split your data in an 80/20 split so that you have a train dataset and a validation dataset from this folder. Load your test dataset from `test/`.\n",
    "\n",
    "You can test the shape of your tensors in the dataset like so:\n",
    "\n",
    "```python\n",
    "batch_X, batch_y = next(iter(train_dataset))\n",
    "print(batch_X.shape, batch_y.shape)\n",
    "```\n",
    "\n",
    "Make sure your shape output makes sense!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC0VML4YLUyL"
   },
   "source": [
    "## Create the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dEHfiurLdLA"
   },
   "source": [
    "Define an FCN network by completing the class definition below.\n",
    "\n",
    "Use a ResNet34 pretrained on ImageNet as the backbone, taking care to remove the final pooling layer and dense layer.\n",
    "\n",
    "Make sure that the FCN head's tensor input size is the same as the backbone's output size.\n",
    "\n",
    "Specify the FCN head with two layers:\n",
    "+ a 1x1 convolution layer, to transform the number of output channels into the number of segmentation classes\n",
    "+ a transpose convolution layer to upsample the feature maps to the size of the input image. Add a bilinear interpolation here if you need it (I did not work out the math on the image sizing, that's left to you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDD-gFf0MRBT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pX-wmwNwMLWg"
   },
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, backbone, head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify that you can load a single image and pass it through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are like a system of pipes. This section is here as a sanity check to ensure that your layers are assembled correct enough for information to flow from top to bottom before you do anything more. \n",
    "\n",
    "Also, have you taken care of ImageNet normalization and the variable image sizes in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain a baseline performance of your FCN network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an appropriate metric to gauge your FCN network's performance, then measure baseline performance on the testing set. Your FCN head is untrained at this point, so its performance should not be flattering. But you'll change that in the next section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetune this FCN network using data in `leaf-segmentation-dataset/trainval`. Store the following info every 10 minibatches: loss (choose an appropriate loss function), intersection over union (Jaccard's index), and Dice loss. During training, collect the above metrics on both your train dataset and your validation dataset. When you are done training, check your network performance on your test dataset.\n",
    "\n",
    "Make sure you are running on GPU! Use Google Colab if you don't have access to a GPU computer. Will leave it to you on exactly how you want to implement finetuning. Run finetuning that will finish within 15, 20 minutes, don't need to finetune for too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxCxD2J9cWjh"
   },
   "source": [
    "## Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5GcGPjQcXhI"
   },
   "source": [
    "Summarize what you did above, as well as detail the choices you made and why. Concise descriptions in one paragraph is enough :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1AuOqwjcnDZ"
   },
   "source": [
    "## EX: Residual pathways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x5lEJmoRcpIr"
   },
   "source": [
    "Here's something for you if you want to explore further.\n",
    "\n",
    "FCNs are very simple and have some key architectural limitations. Depending on how your structured your network or processed your images, you might hit a performance limit even in this fairly simple dataset, even if you implement aggressive augmentations (_what's that?_). Try circumventing these limitations by implementing residual connections (_google me!_) in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
